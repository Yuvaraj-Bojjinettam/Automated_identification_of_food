{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNfAjewgVpP59g6vEqt4HCR"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Import the drive module from google.colab\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount your Google Drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "lKCQbLCyv-F_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
        "\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "82Zfpe4awD03"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, GlobalAveragePooling2D, SimpleRNN, LSTM, TimeDistributed\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import random\n",
        "\n",
        "# Define the image size\n",
        "IMG_SIZE = 224\n",
        "\n",
        "# Define directories\n",
        "base_dir = '/content/drive/MyDrive/Food Detection.v1-food-detection.retinanet (1)/'\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "valid_dir = os.path.join(base_dir, 'valid')\n",
        "test_dir = os.path.join(base_dir, 'test')\n",
        "\n",
        "# Load annotations\n",
        "def load_annotations(directory):\n",
        "    annotations_path = os.path.join(directory, '_annotations.csv')\n",
        "    if os.path.exists(annotations_path):\n",
        "        annotations = pd.read_csv(annotations_path, header=None, sep=\",\")\n",
        "        print(f\"First few rows of annotations:\\n{annotations.head()}\")\n",
        "        annotations.columns = ['filename', 'xmin', 'ymin', 'xmax', 'ymax', 'class']\n",
        "        return annotations\n",
        "    else:\n",
        "        raise FileNotFoundError(f\"No annotation file found in directory {directory}\")\n",
        "\n",
        "train_annotations = load_annotations(train_dir)\n",
        "valid_annotations = load_annotations(valid_dir)\n",
        "test_annotations = load_annotations(test_dir)\n",
        "\n",
        "# Ensure labels are treated as strings\n",
        "train_annotations['class'] = train_annotations['class'].astype(str)\n",
        "valid_annotations['class'] = valid_annotations['class'].astype(str)\n",
        "test_annotations['class'] = test_annotations['class'].astype(str)\n",
        "\n",
        "# Create a combined set of labels from all datasets\n",
        "all_labels = set(train_annotations['class']).union(set(valid_annotations['class'])).union(set(test_annotations['class']))\n",
        "\n",
        "# Create a label map based on all unique labels\n",
        "label_names = sorted(all_labels)\n",
        "label_map = {name: index for index, name in enumerate(label_names)}"
      ],
      "metadata": {
        "id": "ezOGTH9QwHd_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "First few rows of annotations:\n",
        "                                                   0    1    2    3    4  \\\n",
        "0   6219_jpg.rf.f2e1f1588186c338271cde6bb6d39591.jpg  169    0  415  339   \n",
        "1  36042_jpg.rf.f01a1e0ef9bb3a183f82590c08d61cdf.jpg  202    1  387  191   \n",
        "2  307941_jpg.rf.f0aa456a97c4f080d6fa78194085e411...    0   96  151  244   \n",
        "3  307941_jpg.rf.f0aa456a97c4f080d6fa78194085e411...   87  130  283  344   \n",
        "4  307941_jpg.rf.f0aa456a97c4f080d6fa78194085e411...  285  106  415  387   \n",
        "\n",
        "            5  \n",
        "0  Cheesecake  \n",
        "1       Steak  \n",
        "2    Macarons  \n",
        "3    Macarons  \n",
        "4    Macarons  \n",
        "First few rows of annotations:\n",
        "                                                   0    1    2    3    4  \\\n",
        "0  232335_jpg.rf.00120909e356a1850422e77551141428...   21  101  326  378   \n",
        "1  176508_jpg.rf.189bc4a850a5e4c8470731b57c66a240...   95  198  179  351   \n",
        "2  176508_jpg.rf.189bc4a850a5e4c8470731b57c66a240...  159  181  362  390   \n",
        "3  148361_jpg.rf.0e115e9a46a2761676e2d2a05ae4a61a...  297   27  374  200   \n",
        "4  148361_jpg.rf.0e115e9a46a2761676e2d2a05ae4a61a...    8   21   87  224   \n",
        "\n",
        "          5  \n",
        "0  Tiramisu  \n",
        "1     Steak  \n",
        "2     Steak  \n",
        "3  Macarons  \n",
        "4  Macarons  \n",
        "First few rows of annotations:\n",
        "                                                   0    1    2    3    4  \\\n",
        "0  248448_jpg.rf.55349c6550edbabfcfff10a8bcc49b5a...   56   69  331  348   \n",
        "1  129895_jpg.rf.75dd03e871714ec9250fed6a567f1c31...  310   79  376  180   \n",
        "2  129895_jpg.rf.75dd03e871714ec9250fed6a567f1c31...  261   86  328  203   \n",
        "3  129895_jpg.rf.75dd03e871714ec9250fed6a567f1c31...  215  104  281  207   \n",
        "4  129895_jpg.rf.75dd03e871714ec9250fed6a567f1c31...  166  120  225  235   \n",
        "\n",
        "               5  \n",
        "0     Cheesecake  \n",
        "1       Macarons  \n",
        "2  Macarons-Pink  \n",
        "3       Macarons  \n",
        "4   Macarons-Red  \n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "3SJxRc2YwSyr"
      }
    }
  ]
}